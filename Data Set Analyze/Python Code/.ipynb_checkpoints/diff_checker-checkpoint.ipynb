{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import seaborn as sn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from graphviz import Source\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import (RandomOverSampler, SMOTE, ADASYN)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"../../tstat_labels_indexes.txt\" ,'r')\n",
    "data_field_list = []\n",
    "for line in infile.readlines():\n",
    "    if \":\" in line:\n",
    "        data_field = str(re.search('%s(.*)%s' % (\"\\\"\", \"\\\"\"), line).group(1))\n",
    "        index = int(re.search('%s(.*)%s' % (\":\", \",\"), line).group(1))\n",
    "        data_field_list.append((data_field, index))\n",
    "\n",
    "index_to_key_dict = {}\n",
    "key_to_index_dict = {}\n",
    "data_field_labels = []\n",
    "for data_field, index in data_field_list:\n",
    "    key_to_index_dict[data_field] = index\n",
    "    index_to_key_dict[index] = data_field\n",
    "    data_field_labels.append(data_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_file(file_name):\n",
    "    infile = open(file_name, 'r')\n",
    "    header = infile.readline().split(' ')\n",
    "    entries = []\n",
    "    labels = None\n",
    "    for i, line in enumerate(infile.readlines()):\n",
    "        row = get_data_row(line)\n",
    "        row = clean_data_row(row)\n",
    "        if row != []:\n",
    "            entries.append(row)\n",
    "    entries = np.array(entries)\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_row(line):\n",
    "    global index_to_key_dict\n",
    "    line = line.split(' ')\n",
    "    row = []\n",
    "    labels = []\n",
    "    c_pkt_cnt = 0\n",
    "    s_pkt_cnt = 0\n",
    "    c_bytes_cnt = 0\n",
    "    s_bytes_cnt = 0\n",
    "    for data_field, index in data_field_list:\n",
    "        #print(\"df:\", data_field,\"ix:\",index)\n",
    "        #print(line)\n",
    "        \n",
    "        \n",
    "        if data_field == \"client_pkt_cnt\":\n",
    "            try:\n",
    "                c_pkt_cnt = line[index]\n",
    "                c_pkt_cnt = max(float(c_pkt_cnt), 1)\n",
    "            except:\n",
    "                c_pkt_cnt = 1\n",
    "            #if c_pkt_cnt < 32:\n",
    "            #    return []\n",
    "        elif data_field == \"serv_pkt_cnt\":\n",
    "            try:\n",
    "                s_pkt_cnt = line[index]\n",
    "                s_pkt_cnt = max(float(s_pkt_cnt), 1)\n",
    "            except:\n",
    "                s_pkt_cnt = 1\n",
    "        elif data_field == \"client_bytes_cnt\":\n",
    "            try:\n",
    "                c_bytes_cnt = line[index]\n",
    "                c_bytes_cnt = max(float(c_bytes_cnt), 1)\n",
    "            except:\n",
    "                c_bytes_cnt = 1\n",
    "        elif data_field == \"serv_bytes_cnt\":\n",
    "            try:\n",
    "                s_bytes_cnt = line[index]\n",
    "                s_bytes_cnt = max(float(s_bytes_cnt), 1)\n",
    "            except:\n",
    "                s_bytes_cnt = 1\n",
    "                \n",
    "    for data_field, index in data_field_list:\n",
    "        try:\n",
    "            val = line[index]\n",
    "            val = float(val)\n",
    "        except:\n",
    "            val = 0\n",
    "        row.append(val)    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_row(in_row):\n",
    "    global index_to_key_dict, key_to_index_dict\n",
    "    return in_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_count_threshold = 200\n",
    "def get_dataset(path):\n",
    "    out_data = []\n",
    "    file = open('summary.out', 'w')\n",
    "    for sub_dir in os.listdir(path):\n",
    "        temp_path = os.path.join(path, sub_dir)\n",
    "        temp_path = os.path.join(temp_path, \"log_tcp_complete\")\n",
    "        if os.path.isfile(temp_path): \n",
    "            temp_data = np.nan_to_num(read_in_file(temp_path))\n",
    "            rows_before = temp_data.shape[0]\n",
    "            if rows_before == 0:\n",
    "                continue\n",
    "            temp_data = temp_data[temp_data[:,2] > packet_count_threshold]\n",
    "            rows_after = temp_data.shape[0]\n",
    "            print (path + \" removed \" + str(rows_before-rows_after) + \"/\" + str(rows_before) + \" rows\")\n",
    "            if len(temp_data) == 0:\n",
    "                continue\n",
    "            if out_data == []:\n",
    "                out_data = temp_data\n",
    "            else:\n",
    "                out_data = np.concatenate((out_data, temp_data))\n",
    "    file.close\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../DataSet/hpc/normal removed 1076/1430 rows\n",
      "../../DataSet/hpc/normal removed 1078/1432 rows\n",
      "../../DataSet/hpc/normal removed 428/441 rows\n",
      "../../DataSet/hpc/corrupt_0.1perc removed 1064/1416 rows\n",
      "../../DataSet/hpc/corrupt_0.1perc removed 359/370 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pooya/conda/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../DataSet/hpc/corrupt_0.1perc removed 1072/1425 rows\n",
      "../../DataSet/hpc/corrupt_0.5perc removed 1069/1413 rows\n",
      "../../DataSet/hpc/corrupt_0.5perc removed 1083/1436 rows\n",
      "../../DataSet/hpc/corrupt_0.5perc removed 436/436 rows\n",
      "../../DataSet/hpc/corrupt_1.0perc removed 1143/1483 rows\n",
      "../../DataSet/hpc/corrupt_1.0perc removed 1092/1445 rows\n",
      "../../DataSet/hpc/corrupt_1.0perc removed 856/1054 rows\n",
      "../../DataSet/hpc/corrupt_1.0perc removed 1007/1329 rows\n",
      "../../DataSet/hpc/delay_1_var_1 removed 636/798 rows\n",
      "../../DataSet/hpc/delay_1_var_1 removed 1270/1590 rows\n",
      "../../DataSet/hpc/delay_5_var_2 removed 860/1103 rows\n",
      "../../DataSet/hpc/delay_5_var_2 removed 1202/1552 rows\n",
      "../../DataSet/hpc/delay_10_var_5 removed 596/763 rows\n",
      "../../DataSet/hpc/delay_10_var_5 removed 1430/1793 rows\n",
      "../../DataSet/hpc/delay_25_var_20 removed 582/717 rows\n",
      "../../DataSet/hpc/delay_25_var_20 removed 1421/1769 rows\n",
      "../../DataSet/hpc/loss_5perc removed 9/9 rows\n",
      "../../DataSet/hpc/loss_5perc removed 2/2 rows\n",
      "../../DataSet/hpc/loss_5perc removed 1202/1542 rows\n",
      "../../DataSet/hpc/loss_5perc removed 108/124 rows\n",
      "../../DataSet/hpc/loss_5perc removed 1734/2083 rows\n",
      "../../DataSet/hpc/loss_5perc removed 880/1145 rows\n",
      "../../DataSet/hpc/loss_5perc removed 1151/1497 rows\n",
      "../../DataSet/hpc/loss_5perc removed 610/758 rows\n",
      "../../DataSet/hpc/loss_5perc removed 1429/1762 rows\n",
      "../../DataSet/hpc/loss_5perc removed 11/11 rows\n",
      "../../DataSet/hpc/loss_5perc removed 1572/1930 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1785/2136 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1625/1945 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1617/1930 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1886/2237 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1198/1538 rows\n",
      "../../DataSet/hpc/loss_10perc removed 22/22 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1196/1536 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1144/1489 rows\n",
      "../../DataSet/hpc/loss_10perc removed 435/539 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1668/2009 rows\n",
      "../../DataSet/hpc/loss_10perc removed 758/975 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1279/1610 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1383/1715 rows\n",
      "../../DataSet/hpc/loss_10perc removed 631/786 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1158/1505 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1153/1499 rows\n",
      "../../DataSet/hpc/loss_10perc removed 658/820 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1206/1546 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1192/1531 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1570/1926 rows\n",
      "../../DataSet/hpc/loss_10perc removed 1517/1858 rows\n",
      "../../DataSet/hpc/loss_15perc removed 1941/2291 rows\n",
      "../../DataSet/hpc/loss_15perc removed 611/768 rows\n",
      "../../DataSet/hpc/loss_15perc removed 6/6 rows\n",
      "../../DataSet/hpc/dup_10perc removed 1130/1484 rows\n",
      "../../DataSet/hpc/dup_10perc removed 40/52 rows\n",
      "../../DataSet/hpc/dup_10perc removed 1133/1486 rows\n",
      "../../DataSet/hpc/dup_20perc removed 1133/1487 rows\n",
      "../../DataSet/hpc/dup_20perc removed 1133/1486 rows\n",
      "../../DataSet/hpc/dup_20perc removed 40/53 rows\n",
      "../../DataSet/hpc/corrupt_0.01 removed 753/873 rows\n",
      "../../DataSet/hpc/corrupt_0.05 removed 753/873 rows\n",
      "../../DataSet/hpc/corrupt_0.1 removed 759/879 rows\n",
      "../../DataSet/hpc/corrupt_0.5 removed 754/876 rows\n",
      "../../DataSet/hpc/duplicate_0.01 removed 755/875 rows\n",
      "../../DataSet/hpc/duplicate_0.05 removed 771/891 rows\n",
      "../../DataSet/hpc/duplicate_0.1 removed 758/878 rows\n",
      "../../DataSet/hpc/duplicate_0.5 removed 758/878 rows\n",
      "../../DataSet/hpc/loss_0.01 removed 800/920 rows\n",
      "../../DataSet/hpc/loss_0.05 removed 758/878 rows\n",
      "../../DataSet/hpc/loss_0.1 removed 755/875 rows\n",
      "../../DataSet/hpc/loss_0.5 removed 785/906 rows\n",
      "../../DataSet/dtn/FINAL_DATA/normal removed 103/103 rows\n",
      "../../DataSet/dtn/FINAL_DATA/normal removed 112/224 rows\n",
      "../../DataSet/dtn/FINAL_DATA/normal removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/normal removed 11/22 rows\n",
      "../../DataSet/dtn/DTN_LONG_DATA/normal removed 353/706 rows\n",
      "../../DataSet/dtn/DTN_LONG_DATA/normal removed 354/708 rows\n",
      "../../DataSet/dtn/DTN_LONG_DATA/normal removed 354/708 rows\n",
      "../../DataSet/dtn/DTN_LONG_DATA/normal removed 18/36 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.1perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.1perc removed 11/23 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.5perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.5perc removed 11/23 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_1.0perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_1.0perc removed 11/23 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_1_var_1 removed 7/13 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_1_var_1 removed 15/26 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_5_var_2 removed 10/18 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_5_var_2 removed 13/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_10_var_5 removed 14/25 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_10_var_5 removed 9/17 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_25_var_20 removed 4/7 rows\n",
      "../../DataSet/dtn/FINAL_DATA/delay_25_var_20 removed 17/28 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_1perc removed 119/238 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_5perc removed 62/91 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_5perc removed 118/208 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_10perc removed 117/191 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_15perc removed 115/183 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_0.1perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_0.1perc removed 11/22 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_1perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_1perc removed 11/22 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_2perc removed 12/24 rows\n",
      "../../DataSet/dtn/FINAL_DATA/dup_2perc removed 11/22 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.01 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.05 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.1 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/corrupt_0.5 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/duplicate_0.01 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/duplicate_0.05 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/duplicate_0.1 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/duplicate_0.5 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_0.01 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_0.05 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_0.1 removed 120/240 rows\n",
      "../../DataSet/dtn/FINAL_DATA/loss_0.5 removed 120/240 rows\n"
     ]
    }
   ],
   "source": [
    "# normal = get_dataset(\"../../DataSet/emulab/normal\")\n",
    "# corr_01 = get_dataset(\"../../DataSet/emulab/corrupt_0.1perc\")\n",
    "# corr_05 =  get_dataset(\"../../DataSet/emulab/corrupt_5perc\")\n",
    "# corr_10 = get_dataset(\"../../DataSet/emulab/corrupt_1.0perc\")\n",
    "# delay_1_1 = get_dataset(\"../../DataSet/emulab/delay_1_var_1\")\n",
    "# delay_5_2 = get_dataset(\"../../DataSet/emulab/delay_5_var_2\")\n",
    "# delay_10_5 = get_dataset(\"../../DataSet/emulab/delay_10_var_5\")\n",
    "# delay_25_20 = get_dataset(\"../../DataSet/emulab/delay_25_var_20\")\n",
    "# drop_1 = get_dataset(\"../../DataSet/emulab/loss_1_perc\")\n",
    "# drop_3 = get_dataset(\"../../DataSet/emulab/loss_5_perc\")\n",
    "# drop_6 = get_dataset(\"../../DataSet/emulab/loss_10_perc\")\n",
    "# dup_1 = get_dataset(\"../../DataSet/emulab/dup_1perc\")\n",
    "# dup_5 = get_dataset(\"../../DataSet/emulab/dup_5perc\")\n",
    "# dup_7 = get_dataset(\"../../DataSet/emulab/dup_7perc\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# emulab_data = np.concatenate((normal, corr_01, corr_05, corr_10, delay_1_1, delay_5_2, delay_10_5, delay_25_20,\n",
    "#                            drop_1, drop_3, drop_6, dup_1, dup_5, dup_7))\n",
    "# print(\"###########\")\n",
    "# print(emulab_data.shape)\n",
    "# print(\"###########\")\n",
    "# pandas_emulab = pd.DataFrame(data=emulab_data, \n",
    "#               columns=data_field_labels)\n",
    "# # emulab_data = MinMaxScaler().fit_transform(pandas_emulab)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hpc_normal = get_dataset(\"../../DataSet/hpc/normal\")\n",
    "hpc_corr_01 = get_dataset(\"../../DataSet/hpc/corrupt_0.1perc\")\n",
    "hpc_corr_05 = get_dataset(\"../../DataSet/hpc/corrupt_0.5perc\")\n",
    "hpc_corr_10 = get_dataset(\"../../DataSet/hpc/corrupt_1.0perc\")\n",
    "hpc_delay_1_1 = get_dataset(\"../../DataSet/hpc/delay_1_var_1\")\n",
    "hpc_delay_5_2 = get_dataset(\"../../DataSet/hpc/delay_5_var_2\")\n",
    "hpc_delay_10_5 = get_dataset(\"../../DataSet/hpc/delay_10_var_5\")\n",
    "hpc_delay_25_20 = get_dataset(\"../../DataSet/hpc/delay_25_var_20\")\n",
    "hpc_drop_01 = get_dataset(\"../../DataSet/hpc/loss_5perc\")\n",
    "hpc_drop_001 = get_dataset(\"../../DataSet/hpc/loss_10perc\")\n",
    "hpc_drop_0005 = get_dataset(\"../../DataSet/hpc/loss_15perc\")\n",
    "hpc_dup_1 = get_dataset(\"../../DataSet/hpc/dup_10perc\")\n",
    "hpc_dup_2 = get_dataset(\"../../DataSet/hpc/dup_20perc\")\n",
    "\n",
    "\n",
    "hpc_corrupt_001 = get_dataset(\"../../DataSet/hpc/corrupt_0.01\")\n",
    "hpc_corrupt_005 = get_dataset(\"../../DataSet/hpc/corrupt_0.05\")\n",
    "hpc_corrupt_01 = get_dataset(\"../../DataSet/hpc/corrupt_0.1\")\n",
    "hpc_corrupt_05 = get_dataset(\"../../DataSet/hpc/corrupt_0.5\")\n",
    "hpc_duplicate_001 = get_dataset(\"../../DataSet/hpc/duplicate_0.01\")\n",
    "hpc_duplicate_005 = get_dataset(\"../../DataSet/hpc/duplicate_0.05\")\n",
    "hpc_duplicate_01 = get_dataset(\"../../DataSet/hpc/duplicate_0.1\")\n",
    "hpc_duplicate_05 = get_dataset(\"../../DataSet/hpc/duplicate_0.5\")\n",
    "hpc_loss_001 = get_dataset(\"../../DataSet/hpc/loss_0.01\")\n",
    "hpc_loss_005 = get_dataset(\"../../DataSet/hpc/loss_0.05\")\n",
    "hpc_loss_01 = get_dataset(\"../../DataSet/hpc/loss_0.1\")\n",
    "hpc_loss_05 = get_dataset(\"../../DataSet/hpc/loss_0.5\")\n",
    "\n",
    "\n",
    "\n",
    "hpc_normal = pd.DataFrame(data=hpc_normal, \n",
    "              columns=data_field_labels)\n",
    "hpc_corrupt_001 = pd.DataFrame(data=hpc_corrupt_001, \n",
    "              columns=data_field_labels)\n",
    "hpc_corrupt_005 = pd.DataFrame(data=hpc_corrupt_005, \n",
    "              columns=data_field_labels)\n",
    "hpc_corrupt_01 = pd.DataFrame(data=hpc_corrupt_01, \n",
    "              columns=data_field_labels)\n",
    "hpc_corrupt_05 = pd.DataFrame(data=hpc_corrupt_05, \n",
    "              columns=data_field_labels)\n",
    "hpc_duplicate_001 = pd.DataFrame(data=hpc_duplicate_001, \n",
    "              columns=data_field_labels)\n",
    "hpc_duplicate_005 = pd.DataFrame(data=hpc_duplicate_005, \n",
    "              columns=data_field_labels)\n",
    "hpc_duplicate_01 = pd.DataFrame(data=hpc_duplicate_01, \n",
    "              columns=data_field_labels)\n",
    "hpc_duplicate_05 = pd.DataFrame(data=hpc_duplicate_05, \n",
    "              columns=data_field_labels)\n",
    "hpc_loss_001 = pd.DataFrame(data=hpc_loss_001, \n",
    "              columns=data_field_labels)\n",
    "hpc_loss_005 = pd.DataFrame(data=hpc_loss_005, \n",
    "              columns=data_field_labels)\n",
    "hpc_loss_01 = pd.DataFrame(data=hpc_loss_01, \n",
    "              columns=data_field_labels)\n",
    "hpc_loss_05 = pd.DataFrame(data=hpc_loss_05, \n",
    "              columns=data_field_labels)\n",
    "\n",
    "\n",
    "dtn_normal = get_dataset(\"../../DataSet/dtn/FINAL_DATA/normal\")\n",
    "dtn_normal2 = get_dataset(\"../../DataSet/dtn/DTN_LONG_DATA/normal\")\n",
    "dtn_corr_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.1perc\")\n",
    "dtn_corr_05 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.5perc\")\n",
    "dtn_corr_10 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_1.0perc\")\n",
    "dtn_delay_1_1 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/delay_1_var_1\")\n",
    "dtn_delay_5_2 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/delay_5_var_2\")\n",
    "dtn_delay_10_5 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/delay_10_var_5\")\n",
    "dtn_delay_25_20 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/delay_25_var_20\")\n",
    "dtn_drop_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_1perc\")\n",
    "dtn_drop_5 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_5perc\")\n",
    "dtn_drop_10 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_10perc\")\n",
    "dtn_drop_15 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_15perc\")\n",
    "dtn_dup_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/dup_0.1perc\")\n",
    "dtn_dup_1 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/dup_1perc\")\n",
    "dtn_dup_2 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/dup_2perc\")\n",
    "\n",
    "dtn_corrupt_001 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.01\")\n",
    "dtn_corrupt_005 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.05\")\n",
    "dtn_corrupt_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.1\")\n",
    "dtn_corrupt_05 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/corrupt_0.5\")\n",
    "dtn_duplicate_001 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/duplicate_0.01\")\n",
    "dtn_duplicate_005 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/duplicate_0.05\")\n",
    "dtn_duplicate_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/duplicate_0.1\")\n",
    "dtn_duplicate_05 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/duplicate_0.5\")\n",
    "dtn_loss_001 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_0.01\")\n",
    "dtn_loss_005 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_0.05\")\n",
    "dtn_loss_01 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_0.1\")\n",
    "dtn_loss_05 = get_dataset(\"../../DataSet/dtn/FINAL_DATA/loss_0.5\")\n",
    "\n",
    "\n",
    "\n",
    "dtn_normal = pd.DataFrame(data=dtn_normal, \n",
    "              columns=data_field_labels)\n",
    "dtn_corrupt_001 = pd.DataFrame(data=dtn_corrupt_001, \n",
    "              columns=data_field_labels)\n",
    "dtn_corrupt_005 = pd.DataFrame(data=dtn_corrupt_005, \n",
    "              columns=data_field_labels)\n",
    "dtn_corrupt_01 = pd.DataFrame(data=dtn_corrupt_01, \n",
    "              columns=data_field_labels)\n",
    "dtn_corrupt_05 = pd.DataFrame(data=dtn_corrupt_05, \n",
    "              columns=data_field_labels)\n",
    "dtn_duplicate_001 = pd.DataFrame(data=dtn_duplicate_001, \n",
    "              columns=data_field_labels)\n",
    "dtn_duplicate_005 = pd.DataFrame(data=dtn_duplicate_005, \n",
    "              columns=data_field_labels)\n",
    "dtn_duplicate_01 = pd.DataFrame(data=dtn_duplicate_01, \n",
    "              columns=data_field_labels)\n",
    "dtn_duplicate_05 = pd.DataFrame(data=dtn_duplicate_05, \n",
    "              columns=data_field_labels)\n",
    "dtn_loss_001 = pd.DataFrame(data=dtn_loss_001, \n",
    "              columns=data_field_labels)\n",
    "dtn_loss_005 = pd.DataFrame(data=dtn_loss_005, \n",
    "              columns=data_field_labels)\n",
    "dtn_loss_01 = pd.DataFrame(data=dtn_loss_01, \n",
    "              columns=data_field_labels)\n",
    "dtn_loss_05 = pd.DataFrame(data=dtn_loss_05, \n",
    "              columns=data_field_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_pkt_cnt        7.54146e+06\n",
      "client_rst_cnt                  0\n",
      "client_ack_cnt        7.54074e+06\n",
      "client_ack_pkt_cnt            942\n",
      "client_bytes_uniq     4.87786e+11\n",
      "dtype: object\n",
      "(446,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "client_pkt_cnt        6.034872e+07\n",
       "client_rst_cnt        0.000000e+00\n",
       "client_ack_cnt        6.034860e+07\n",
       "client_ack_pkt_cnt    1.230000e+02\n",
       "client_bytes_uniq     2.609398e+12\n",
       "client_pkt_data       6.034848e+07\n",
       "client_bytes_cnt      2.613377e+12\n",
       "client_pkt_retx       2.705570e+05\n",
       "client_bytes_retx     3.979687e+09\n",
       "client_syn_cnt        1.200000e+02\n",
       "client_fin_cnt        0.000000e+00\n",
       "client_pkt_retx       0.000000e+00\n",
       "serv_pkt_cnt          3.548757e+07\n",
       "serv_rst_cnt          1.200000e+02\n",
       "serv_ack_cnt          3.548753e+07\n",
       "serv_ack_pck_cnt      3.548730e+07\n",
       "serv_bytes_uniq       0.000000e+00\n",
       "serv_pkts_data        0.000000e+00\n",
       "serv_bytes_cnt        0.000000e+00\n",
       "serv_pkts_retx        0.000000e+00\n",
       "serv_bytes_retx       0.000000e+00\n",
       "serv_syn_cnt          1.200000e+02\n",
       "serv_fin_cnt          3.200000e+01\n",
       "serv_dur              2.405333e+06\n",
       "client_first          1.836000e+01\n",
       "serv_first            0.000000e+00\n",
       "client_last           2.405319e+06\n",
       "serv_last             0.000000e+00\n",
       "client_f_ack          1.451800e+01\n",
       "serv_f_ack            2.522600e+01\n",
       "                          ...     \n",
       "c_pkt_dup             0.000000e+00\n",
       "c_pkt_unk             2.639770e+05\n",
       "c_pkt_fc              0.000000e+00\n",
       "c_pkt_unrto           2.000000e+00\n",
       "c_pkt_unfs            1.346000e+03\n",
       "c_syn_retx            0.000000e+00\n",
       "s_tm_opt              1.200000e+02\n",
       "s_win_scl             1.560000e+03\n",
       "s_sack_opt            1.200000e+02\n",
       "s_sack_cnt            4.250305e+06\n",
       "s_mss                 1.752000e+05\n",
       "s_mss_max             0.000000e+00\n",
       "s_mss_min             0.000000e+00\n",
       "s_win_max             1.159078e+09\n",
       "s_win_min             1.034672e+06\n",
       "s_win_0               1.462500e+04\n",
       "s_cwin_max            0.000000e+00\n",
       "s_cwin_min            0.000000e+00\n",
       "s_cwin_ini            0.000000e+00\n",
       "s_pkt_rt0             0.000000e+00\n",
       "s_pkt_fs              0.000000e+00\n",
       "s_pkt_reor            0.000000e+00\n",
       "s_pkt_dup             0.000000e+00\n",
       "s_pkt_unk             0.000000e+00\n",
       "s_pkt_fc              0.000000e+00\n",
       "s_pkt_unrto           0.000000e+00\n",
       "s_pkt_unfs            0.000000e+00\n",
       "s_syn_retx            0.000000e+00\n",
       "c_pkts_push           3.893800e+04\n",
       "s_pkts_push           0.000000e+00\n",
       "Length: 89, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hpc_normal = hpc_normal.sum()\n",
    "hpc_corrupt_001 = hpc_corrupt_001.sum()\n",
    "hpc_corrupt_005 = hpc_corrupt_005.sum()\n",
    "hpc_corrupt_01 = hpc_corrupt_01.sum()\n",
    "hpc_corrupt_05 = hpc_corrupt_05.sum()\n",
    "\n",
    "\n",
    "\n",
    "df4 = pd.concat([hpc_normal.T, hpc_corrupt_001.T, hpc_corrupt_005.T, hpc_corrupt_01.T, hpc_corrupt_05.T]\n",
    "                , axis=0, ignore_index=False)\n",
    "df4['col'] = (len(hpc_normal.T)*(0,) + len(hpc_corrupt_001.T)*(1,)+ len(hpc_corrupt_005.T)*(2,)\n",
    "              + len(hpc_corrupt_01.T)*(3,)+ len(hpc_corrupt_05.T)*(4,))\n",
    "\n",
    "print(df4.shape)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "print(df4.shape)\n",
    "# sns.factorplot(x=data_field_labels, y='A', hue='col', kind='bar', data=df4)\n",
    "\n",
    "\n",
    "\n",
    "# hpc_duplicate_001.sum()\n",
    "# hpc_duplicate_005.sum()\n",
    "# hpc_duplicate_01.sum()\n",
    "# hpc_duplicate_05.sum()\n",
    "\n",
    "# hpc_loss_001.sum()\n",
    "# hpc_loss_005.sum()\n",
    "# hpc_loss_01.sum()\n",
    "# hpc_loss_05.sum()\n",
    "\n",
    "# dtn_normal.sum()\n",
    "# dtn_corrupt_001.sum()\n",
    "# dtn_corrupt_005.sum()\n",
    "# dtn_corrupt_01.sum()\n",
    "# dtn_corrupt_05.sum()\n",
    "# dtn_duplicate_001.sum()\n",
    "# dtn_duplicate_005.sum()\n",
    "# dtn_duplicate_01.sum()\n",
    "# dtn_duplicate_05.sum()\n",
    "# dtn_loss_001.sum()\n",
    "# dtn_loss_005.sum()\n",
    "# dtn_loss_01.sum()\n",
    "# dtn_loss_05.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
